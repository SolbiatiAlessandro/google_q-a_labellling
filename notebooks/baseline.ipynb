{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading PreTrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('../data')\n",
    "TEST_PATH = \"../data/test.csv\"\n",
    "TRAIN_PATH = \"../data/train.csv\"\n",
    "SAMPLE_SUBMISSION_PATH = \"../data/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "sample_submission_data = pd.read_csv(SAMPLE_SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "['qa_id', 'question_title', 'question_body', 'question_user_name', 'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', 'url', 'category', 'host']\n"
     ]
    }
   ],
   "source": [
    "prediction_columns = [col for col in train_data.columns if col not in test_data]\n",
    "input_columns = [col for col in test_data.columns]\n",
    "print(prediction_columns)\n",
    "print(input_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "BERT_BASE_UNCASED_LOCATION = \"../models/bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(BERT_BASE_UNCASED_LOCATION, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-BERT features preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_data[input_columns], train_data[prediction_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_category_encoder = preprocessing.OneHotEncoder(drop='first').fit(X[['host', 'category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_category_encoding = host_category_encoder.transform(X[['host', 'category']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert host_category_encoding.shape[1] == len(X['host'].unique()) + len(X['category'].unique()) - 2\n",
    "assert host_category_encoding.shape[0] == len(X['host'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_non_BERT_features = pd.concat([pd.DataFrame(host_category_encoding), X['question_title'].map(len), X['question_body'].map(len), X['answer'].map(len)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>836</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108</td>\n",
       "      <td>789</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>653</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>425</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>416</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>393</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>581</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>693</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>922</td>\n",
       "      <td>1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>314</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6079 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...   59   60   61  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "6074  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6075  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6076  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6077  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "6078  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       62   63   64   65  question_title  question_body  answer  \n",
       "0     1.0  0.0  0.0  0.0              68            836     833  \n",
       "1     0.0  0.0  0.0  0.0             108            789     451  \n",
       "2     0.0  1.0  0.0  0.0              56            653    1048  \n",
       "3     0.0  0.0  0.0  0.0              37            425    1337  \n",
       "4     1.0  0.0  0.0  0.0              44            416     225  \n",
       "...   ...  ...  ...  ...             ...            ...     ...  \n",
       "6074  0.0  0.0  0.0  0.0              36            393    1309  \n",
       "6075  0.0  0.0  0.0  0.0              54            581    1122  \n",
       "6076  0.0  0.0  0.0  1.0              50            693     134  \n",
       "6077  0.0  1.0  0.0  0.0              40            922    1429  \n",
       "6078  1.0  0.0  0.0  0.0              76            314    1129  \n",
       "\n",
       "[6079 rows x 69 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_non_BERT_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-BERT features linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "assert X_non_BERT_features.shape[0] == y.shape[0]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_non_BERT_features, y)\n",
    "\n",
    "assert len(X_non_BERT_features) == len(X_train) + len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "non_BERT_linear_regression = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred = non_BERT_linear_regression.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "\n",
    "assert len(y_test) == len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    assert y_test.shape == y_pred.shape\n",
    "    correlations = [stats.spearmanr(y_test.iloc[:, col_index], y_pred.iloc[:, col_index]).correlation for col_index in range(y_test.shape[1])]\n",
    "    score = sum([*filter(lambda x: not math.isnan(x), correlations)]) / len([*filter(lambda x: not math.isnan(x), correlations)])\n",
    "    return score, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lessandro/Coding/KAGGLE/QUEST/venv/lib/python3.7/site-packages/scipy/stats/stats.py:4196: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2614393768250053"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, correlations = evaluate(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst predicted columns are: answer_relevance, question_not_really_a_question, answer_plausible\n",
      "top predicted columns are:  question_type_instructions,  question_type_spelling,  answer_type_instructions\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def visualise_correlations(correlations):\n",
    "    worst_columns = [prediction_columns[correlations.index(corr)] for corr in sorted(correlations)[:3]]\n",
    "    top_columns = [prediction_columns[correlations.index(corr)] for corr in sorted(correlations)[-3:]]\n",
    "    print(\"worst predicted columns are: \" + ', '.join(worst_columns))\n",
    "    print(\"top predicted columns are:  \" + ',  '.join(top_columns))\n",
    "    plt.plot(correlations, marker='o')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"Correlation score for each column\", c=\"w\")\n",
    "    plt.show()\n",
    "    \n",
    "visualise_correlations(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
